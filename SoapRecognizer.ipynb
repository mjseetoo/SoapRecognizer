{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4810ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n",
      "Image resized successfully!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_image(image_path, output_path, size=(400, 400)):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize(size)\n",
    "        img.save(output_path)\n",
    "        print(\"Image resized successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error resizing image: {e}\")\n",
    "\n",
    "\n",
    "x = 0\n",
    "\n",
    "while x <= 30:\n",
    "    input_image_path = \"images/images/input_image\" + str(x) + \".jpg\"\n",
    "    output_image_path = \"output/\" + str(x) + \".jpg\"\n",
    "    resize_image(input_image_path, output_image_path)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fcfe3f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.0-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: torch==2.2.0 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (2.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (1.10.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (2022.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\micah\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.0->torchvision) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\micah\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.0->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a86aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 50 * 50, 128)  # Adjusted input size to match the output of conv3\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Read labels from the text file\n",
    "        with open(os.path.join(self.root_dir, \"labels.txt\"), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                image_name = parts[0]  # First part is the image name\n",
    "                \n",
    "                # Join remaining parts to form label (handling cases like \"not soap\")\n",
    "                label = \" \".join(parts[1:])\n",
    "                \n",
    "                # Append file extension to the image path\n",
    "                image_path = os.path.join(self.root_dir, f\"{image_name}.jpg\")\n",
    "                self.image_paths.append(image_path)\n",
    "                \n",
    "                # Map string labels to integers\n",
    "                if label == \"soap\":\n",
    "                    self.labels.append(0)\n",
    "                elif label == \"not_soap\":\n",
    "                    self.labels.append(1)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown label: {label}\")\n",
    "\n",
    "                # Print image paths and labels for debugging\n",
    "                print(f\"Image path: {self.image_paths[-1]}, Label: {self.labels[-1]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    \n",
    "# Specify device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify dataset directory\n",
    "dataset_dir = \"output\"\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = CustomDataset(root_dir=dataset_dir, transform=transform)\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create data loader\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = 2 # assuming 2 classes: soap and not soap\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23454b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path: output\\0.jpg, Label: 0\n",
      "Image path: output\\1.jpg, Label: 0\n",
      "Image path: output\\2.jpg, Label: 1\n",
      "Image path: output\\3.jpg, Label: 0\n",
      "Image path: output\\4.jpg, Label: 1\n",
      "Image path: output\\5.jpg, Label: 1\n",
      "Image path: output\\6.jpg, Label: 1\n",
      "Image path: output\\7.jpg, Label: 0\n",
      "Image path: output\\8.jpg, Label: 0\n",
      "Image path: output\\9.jpg, Label: 0\n",
      "Image path: output\\10.jpg, Label: 1\n",
      "Image path: output\\11.jpg, Label: 1\n",
      "Image path: output\\12.jpg, Label: 0\n",
      "Image path: output\\13.jpg, Label: 0\n",
      "Image path: output\\14.jpg, Label: 0\n",
      "Image path: output\\15.jpg, Label: 1\n",
      "Image path: output\\16.jpg, Label: 1\n",
      "Image path: output\\17.jpg, Label: 1\n",
      "Image path: output\\18.jpg, Label: 0\n",
      "Image path: output\\19.jpg, Label: 0\n",
      "Image path: output\\20.jpg, Label: 0\n",
      "Image path: output\\21.jpg, Label: 1\n",
      "Image path: output\\22.jpg, Label: 1\n",
      "Image path: output\\23.jpg, Label: 1\n",
      "Image path: output\\24.jpg, Label: 0\n",
      "Image path: output\\25.jpg, Label: 0\n",
      "Image path: output\\26.jpg, Label: 0\n",
      "Image path: output\\27.jpg, Label: 0\n",
      "Image path: output\\28.jpg, Label: 1\n",
      "Image path: output\\29.jpg, Label: 1\n",
      "Image path: output\\30.jpg, Label: 1\n",
      "Epoch [1/10], Average Loss: 0.024\n",
      "Epoch [1/10], Average Loss: 0.314\n",
      "Epoch [1/10], Average Loss: 0.376\n",
      "Epoch [1/10], Average Loss: 0.427\n",
      "Epoch [1/10], Average Loss: 0.442\n",
      "Epoch [1/10], Average Loss: 0.473\n",
      "Epoch [1/10], Average Loss: 0.499\n",
      "Epoch [1/10], Average Loss: 0.521\n",
      "Epoch [1/10], Average Loss: 0.544\n",
      "Epoch [1/10], Batch [10/31], Loss: 1.752\n",
      "Epoch [1/10], Average Loss: 0.000\n",
      "Epoch [1/10], Average Loss: 0.024\n",
      "Epoch [1/10], Average Loss: 0.049\n",
      "Epoch [1/10], Average Loss: 0.069\n",
      "Epoch [1/10], Average Loss: 0.090\n",
      "Epoch [1/10], Average Loss: 0.110\n",
      "Epoch [1/10], Average Loss: 0.135\n",
      "Epoch [1/10], Average Loss: 0.155\n",
      "Epoch [1/10], Average Loss: 0.175\n",
      "Epoch [1/10], Average Loss: 0.195\n",
      "Epoch [1/10], Batch [20/31], Loss: 0.682\n",
      "Epoch [1/10], Average Loss: 0.000\n",
      "Epoch [1/10], Average Loss: 0.020\n",
      "Epoch [1/10], Average Loss: 0.041\n",
      "Epoch [1/10], Average Loss: 0.065\n",
      "Epoch [1/10], Average Loss: 0.090\n",
      "Epoch [1/10], Average Loss: 0.115\n",
      "Epoch [1/10], Average Loss: 0.139\n",
      "Epoch [1/10], Average Loss: 0.164\n",
      "Epoch [1/10], Average Loss: 0.184\n",
      "Epoch [1/10], Average Loss: 0.204\n",
      "Epoch [1/10], Batch [30/31], Loss: 0.710\n",
      "Epoch [1/10], Average Loss: 0.000\n",
      "Epoch [1/10], Average Loss: 0.024\n",
      "Epoch [2/10], Average Loss: 0.021\n",
      "Epoch [2/10], Average Loss: 0.044\n",
      "Epoch [2/10], Average Loss: 0.065\n",
      "Epoch [2/10], Average Loss: 0.086\n",
      "Epoch [2/10], Average Loss: 0.106\n",
      "Epoch [2/10], Average Loss: 0.129\n",
      "Epoch [2/10], Average Loss: 0.150\n",
      "Epoch [2/10], Average Loss: 0.173\n",
      "Epoch [2/10], Average Loss: 0.193\n",
      "Epoch [2/10], Batch [10/31], Loss: 0.663\n",
      "Epoch [2/10], Average Loss: 0.000\n",
      "Epoch [2/10], Average Loss: 0.019\n",
      "Epoch [2/10], Average Loss: 0.040\n",
      "Epoch [2/10], Average Loss: 0.062\n",
      "Epoch [2/10], Average Loss: 0.084\n",
      "Epoch [2/10], Average Loss: 0.107\n",
      "Epoch [2/10], Average Loss: 0.123\n",
      "Epoch [2/10], Average Loss: 0.147\n",
      "Epoch [2/10], Average Loss: 0.150\n",
      "Epoch [2/10], Average Loss: 0.165\n",
      "Epoch [2/10], Batch [20/31], Loss: 0.599\n",
      "Epoch [2/10], Average Loss: 0.000\n",
      "Epoch [2/10], Average Loss: 0.005\n",
      "Epoch [2/10], Average Loss: 0.008\n",
      "Epoch [2/10], Average Loss: 0.008\n",
      "Epoch [2/10], Average Loss: 0.031\n",
      "Epoch [2/10], Average Loss: 0.045\n",
      "Epoch [2/10], Average Loss: 0.108\n",
      "Epoch [2/10], Average Loss: 0.108\n",
      "Epoch [2/10], Average Loss: 0.126\n",
      "Epoch [2/10], Average Loss: 0.146\n",
      "Epoch [2/10], Batch [30/31], Loss: 0.523\n",
      "Epoch [2/10], Average Loss: 0.000\n",
      "Epoch [2/10], Average Loss: 0.025\n",
      "Epoch [3/10], Average Loss: 0.022\n",
      "Epoch [3/10], Average Loss: 0.028\n",
      "Epoch [3/10], Average Loss: 0.042\n",
      "Epoch [3/10], Average Loss: 0.062\n",
      "Epoch [3/10], Average Loss: 0.070\n",
      "Epoch [3/10], Average Loss: 0.091\n",
      "Epoch [3/10], Average Loss: 0.101\n",
      "Epoch [3/10], Average Loss: 0.124\n",
      "Epoch [3/10], Average Loss: 0.145\n",
      "Epoch [3/10], Batch [10/31], Loss: 0.524\n",
      "Epoch [3/10], Average Loss: 0.000\n",
      "Epoch [3/10], Average Loss: 0.011\n",
      "Epoch [3/10], Average Loss: 0.038\n",
      "Epoch [3/10], Average Loss: 0.059\n",
      "Epoch [3/10], Average Loss: 0.060\n",
      "Epoch [3/10], Average Loss: 0.087\n",
      "Epoch [3/10], Average Loss: 0.087\n",
      "Epoch [3/10], Average Loss: 0.088\n",
      "Epoch [3/10], Average Loss: 0.088\n",
      "Epoch [3/10], Average Loss: 0.108\n",
      "Epoch [3/10], Batch [20/31], Loss: 0.424\n",
      "Epoch [3/10], Average Loss: 0.000\n",
      "Epoch [3/10], Average Loss: 0.000\n",
      "Epoch [3/10], Average Loss: 0.020\n",
      "Epoch [3/10], Average Loss: 0.020\n",
      "Epoch [3/10], Average Loss: 0.020\n",
      "Epoch [3/10], Average Loss: 0.040\n",
      "Epoch [3/10], Average Loss: 0.040\n",
      "Epoch [3/10], Average Loss: 0.060\n",
      "Epoch [3/10], Average Loss: 0.121\n",
      "Epoch [3/10], Average Loss: 0.142\n",
      "Epoch [3/10], Batch [30/31], Loss: 0.442\n",
      "Epoch [3/10], Average Loss: 0.000\n",
      "Epoch [3/10], Average Loss: 0.019\n",
      "Epoch [4/10], Average Loss: 0.000\n",
      "Epoch [4/10], Average Loss: 0.006\n",
      "Epoch [4/10], Average Loss: 0.038\n",
      "Epoch [4/10], Average Loss: 0.059\n",
      "Epoch [4/10], Average Loss: 0.079\n",
      "Epoch [4/10], Average Loss: 0.098\n",
      "Epoch [4/10], Average Loss: 0.118\n",
      "Epoch [4/10], Average Loss: 0.137\n",
      "Epoch [4/10], Average Loss: 0.151\n",
      "Epoch [4/10], Batch [10/31], Loss: 0.536\n",
      "Epoch [4/10], Average Loss: 0.000\n",
      "Epoch [4/10], Average Loss: 0.019\n",
      "Epoch [4/10], Average Loss: 0.039\n",
      "Epoch [4/10], Average Loss: 0.058\n",
      "Epoch [4/10], Average Loss: 0.065\n",
      "Epoch [4/10], Average Loss: 0.085\n",
      "Epoch [4/10], Average Loss: 0.095\n",
      "Epoch [4/10], Average Loss: 0.114\n",
      "Epoch [4/10], Average Loss: 0.133\n",
      "Epoch [4/10], Average Loss: 0.140\n",
      "Epoch [4/10], Batch [20/31], Loss: 0.434\n",
      "Epoch [4/10], Average Loss: 0.000\n",
      "Epoch [4/10], Average Loss: 0.000\n",
      "Epoch [4/10], Average Loss: 0.030\n",
      "Epoch [4/10], Average Loss: 0.044\n",
      "Epoch [4/10], Average Loss: 0.055\n",
      "Epoch [4/10], Average Loss: 0.055\n",
      "Epoch [4/10], Average Loss: 0.055\n",
      "Epoch [4/10], Average Loss: 0.055\n",
      "Epoch [4/10], Average Loss: 0.055\n",
      "Epoch [4/10], Average Loss: 0.132\n",
      "Epoch [4/10], Batch [30/31], Loss: 0.470\n",
      "Epoch [4/10], Average Loss: 0.000\n",
      "Epoch [4/10], Average Loss: 0.023\n",
      "Epoch [5/10], Average Loss: 0.019\n",
      "Epoch [5/10], Average Loss: 0.019\n",
      "Epoch [5/10], Average Loss: 0.024\n",
      "Epoch [5/10], Average Loss: 0.044\n",
      "Epoch [5/10], Average Loss: 0.063\n",
      "Epoch [5/10], Average Loss: 0.082\n",
      "Epoch [5/10], Average Loss: 0.100\n",
      "Epoch [5/10], Average Loss: 0.108\n",
      "Epoch [5/10], Average Loss: 0.127\n",
      "Epoch [5/10], Batch [10/31], Loss: 0.452\n",
      "Epoch [5/10], Average Loss: 0.000\n",
      "Epoch [5/10], Average Loss: 0.000\n",
      "Epoch [5/10], Average Loss: 0.019\n",
      "Epoch [5/10], Average Loss: 0.038\n",
      "Epoch [5/10], Average Loss: 0.038\n",
      "Epoch [5/10], Average Loss: 0.041\n",
      "Epoch [5/10], Average Loss: 0.049\n",
      "Epoch [5/10], Average Loss: 0.049\n",
      "Epoch [5/10], Average Loss: 0.049\n",
      "Epoch [5/10], Average Loss: 0.049\n",
      "Epoch [5/10], Batch [20/31], Loss: 0.336\n",
      "Epoch [5/10], Average Loss: 0.000\n",
      "Epoch [5/10], Average Loss: 0.016\n",
      "Epoch [5/10], Average Loss: 0.034\n",
      "Epoch [5/10], Average Loss: 0.051\n",
      "Epoch [5/10], Average Loss: 0.051\n",
      "Epoch [5/10], Average Loss: 0.065\n",
      "Epoch [5/10], Average Loss: 0.077\n",
      "Epoch [5/10], Average Loss: 0.077\n",
      "Epoch [5/10], Average Loss: 0.077\n",
      "Epoch [5/10], Average Loss: 0.097\n",
      "Epoch [5/10], Batch [30/31], Loss: 0.343\n",
      "Epoch [5/10], Average Loss: 0.000\n",
      "Epoch [5/10], Average Loss: 0.006\n",
      "Epoch [6/10], Average Loss: 0.002\n",
      "Epoch [6/10], Average Loss: 0.002\n",
      "Epoch [6/10], Average Loss: 0.003\n",
      "Epoch [6/10], Average Loss: 0.007\n",
      "Epoch [6/10], Average Loss: 0.088\n",
      "Epoch [6/10], Average Loss: 0.088\n",
      "Epoch [6/10], Average Loss: 0.089\n",
      "Epoch [6/10], Average Loss: 0.457\n",
      "Epoch [6/10], Average Loss: 0.502\n",
      "Epoch [6/10], Batch [10/31], Loss: 1.603\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.039\n",
      "Epoch [6/10], Average Loss: 0.063\n",
      "Epoch [6/10], Average Loss: 0.083\n",
      "Epoch [6/10], Average Loss: 0.086\n",
      "Epoch [6/10], Average Loss: 0.103\n",
      "Epoch [6/10], Average Loss: 0.103\n",
      "Epoch [6/10], Batch [20/31], Loss: 0.346\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.009\n",
      "Epoch [6/10], Average Loss: 0.009\n",
      "Epoch [6/10], Average Loss: 0.014\n",
      "Epoch [6/10], Average Loss: 0.014\n",
      "Epoch [6/10], Average Loss: 0.018\n",
      "Epoch [6/10], Average Loss: 0.018\n",
      "Epoch [6/10], Average Loss: 0.021\n",
      "Epoch [6/10], Batch [30/31], Loss: 0.072\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [6/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.076\n",
      "Epoch [7/10], Average Loss: 0.076\n",
      "Epoch [7/10], Average Loss: 0.076\n",
      "Epoch [7/10], Average Loss: 0.079\n",
      "Epoch [7/10], Average Loss: 0.082\n",
      "Epoch [7/10], Average Loss: 0.082\n",
      "Epoch [7/10], Batch [10/31], Loss: 0.255\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.001\n",
      "Epoch [7/10], Average Loss: 0.003\n",
      "Epoch [7/10], Average Loss: 0.008\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Batch [20/31], Loss: 0.040\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.013\n",
      "Epoch [7/10], Average Loss: 0.016\n",
      "Epoch [7/10], Average Loss: 0.225\n",
      "Epoch [7/10], Average Loss: 0.225\n",
      "Epoch [7/10], Average Loss: 0.225\n",
      "Epoch [7/10], Average Loss: 0.277\n",
      "Epoch [7/10], Batch [30/31], Loss: 0.858\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [7/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.014\n",
      "Epoch [8/10], Average Loss: 0.014\n",
      "Epoch [8/10], Average Loss: 0.014\n",
      "Epoch [8/10], Batch [10/31], Loss: 0.250\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.011\n",
      "Epoch [8/10], Average Loss: 0.011\n",
      "Epoch [8/10], Batch [20/31], Loss: 0.035\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.001\n",
      "Epoch [8/10], Average Loss: 0.003\n",
      "Epoch [8/10], Average Loss: 0.003\n",
      "Epoch [8/10], Average Loss: 0.004\n",
      "Epoch [8/10], Average Loss: 0.006\n",
      "Epoch [8/10], Average Loss: 0.006\n",
      "Epoch [8/10], Average Loss: 0.006\n",
      "Epoch [8/10], Average Loss: 0.048\n",
      "Epoch [8/10], Batch [30/31], Loss: 0.155\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [8/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.001\n",
      "Epoch [9/10], Average Loss: 0.002\n",
      "Epoch [9/10], Average Loss: 0.002\n",
      "Epoch [9/10], Average Loss: 0.003\n",
      "Epoch [9/10], Average Loss: 0.003\n",
      "Epoch [9/10], Average Loss: 0.003\n",
      "Epoch [9/10], Average Loss: 0.003\n",
      "Epoch [9/10], Average Loss: 0.003\n",
      "Epoch [9/10], Average Loss: 0.003\n",
      "Epoch [9/10], Batch [10/31], Loss: 0.011\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.005\n",
      "Epoch [9/10], Average Loss: 0.005\n",
      "Epoch [9/10], Average Loss: 0.005\n",
      "Epoch [9/10], Average Loss: 0.005\n",
      "Epoch [9/10], Average Loss: 0.005\n",
      "Epoch [9/10], Average Loss: 0.005\n",
      "Epoch [9/10], Batch [20/31], Loss: 0.016\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.001\n",
      "Epoch [9/10], Average Loss: 0.001\n",
      "Epoch [9/10], Batch [30/31], Loss: 0.002\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [9/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.001\n",
      "Epoch [10/10], Average Loss: 0.001\n",
      "Epoch [10/10], Average Loss: 0.001\n",
      "Epoch [10/10], Average Loss: 0.001\n",
      "Epoch [10/10], Average Loss: 0.002\n",
      "Epoch [10/10], Average Loss: 0.002\n",
      "Epoch [10/10], Average Loss: 0.002\n",
      "Epoch [10/10], Batch [10/31], Loss: 0.006\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Batch [20/31], Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.024\n",
      "Epoch [10/10], Batch [30/31], Loss: 0.075\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Epoch [10/10], Average Loss: 0.000\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(data_loader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # Print every 10 mini-batches\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Batch [{i + 1}/{len(data_loader)}], Loss: {running_loss / 10:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        epoch_loss = running_loss / len(data_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {epoch_loss:.3f}\")\n",
    "            \n",
    "torch.save(model.state_dict(), \"path_to_save_model.pth\")\n",
    "print(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91b998b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it soap?: soap\n",
      "Is it soap?: not soap\n",
      "Is it soap?: soap\n",
      "Is it soap?: not soap\n",
      "Is it soap?: not soap\n",
      "Is it soap?: soap\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "# Function to resize image\n",
    "def resize_image(input_image_path, output_image_path):\n",
    "    image = Image.open(input_image_path)\n",
    "    resized_image = image.resize((400, 400))\n",
    "    resized_image.save(output_image_path)\n",
    "    return output_image_path\n",
    "\n",
    "# Function to predict class of image\n",
    "def predict_image(image_path, model):\n",
    "    # Open the image and apply the same transformations used during training\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = ToTensor()\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        # Map predicted label index to class name\n",
    "        class_names = [\"soap\", \"not soap\"]\n",
    "        predicted_class = class_names[predicted.item()]\n",
    "        \n",
    "        return predicted_class\n",
    "x = 0 \n",
    "while x <= 5:\n",
    "    input_image_path = \"testimages/test_image\"+str(x)+\".jpg\"\n",
    "    output_image_path = \"testimages/resized_image\"+str(x)+\".jpg\"\n",
    "\n",
    "    # Resize the input image\n",
    "    resized_image_path = resize_image(input_image_path, output_image_path)\n",
    "\n",
    "    # Load the trained model\n",
    "    model = SimpleCNN(num_classes=2)  # Assuming 2 classes: soap and not soap\n",
    "    model.load_state_dict(torch.load(\"path_to_save_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    # Predict the class of the resized image\n",
    "    predicted_class = predict_image(resized_image_path, model)\n",
    "    print(\"Is it soap?:\", predicted_class)\n",
    "    x+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
